# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['cover_agent', 'cover_agent.settings']

package_data = \
{'': ['*']}

install_requires = \
['beautifulsoup4>=4.12.3,<5.0.0',
 'boto3>=1.34.121,<2.0.0',
 'dynaconf>=3.2.4,<4.0.0',
 'google-cloud-aiplatform>=1.54.0,<2.0.0',
 'jinja2>=3.1.3,<4.0.0',
 'litellm @ git+https://github.com/mrT23/litellm.git',
 'numpy>=1.26.0,<2.0.0',
 'openai>=1.32.0,<2.0.0',
 'tiktoken>=0.7.0,<0.8.0',
 'wandb>=0.17.1,<0.18.0']

entry_points = \
{'console_scripts': ['cover-agent = cover_agent.main:main']}

setup_kwargs = {
    'name': 'cover-agent',
    'version': '0.0.0',
    'description': 'Cover Agent Tool',
    'long_description': '<div align="center">\n\n<div align="center">\n\n\n<picture>\n  <source media="(prefers-color-scheme: dark)" srcset="https://www.codium.ai/images/cover-agent/cover-agent-dark.png" width="330">\n  <source media="(prefers-color-scheme: light)" srcset="https://www.codium.ai/images/cover-agent/cover-agent-light.png" width="330">\n  <img src="https://www.codium.ai/images/cover-agent/cover-agent-light.png" alt="logo" width="330">\n\n</picture>\n<br/>\nCodiumAI Cover Agent aims to help efficiently increasing code coverage, by automatically generating qualified tests to enhance existing test suites\n</div>\n\n[![GitHub license](https://img.shields.io/badge/License-AGPL_3.0-blue.svg)](https://github.com/Codium-ai/cover-agent/blob/main/LICENSE)\n[![Discord](https://badgen.net/badge/icon/discord?icon=discord&label&color=purple)](https://discord.gg/cYsvFJJbdM)\n[![Twitter](https://img.shields.io/twitter/follow/codiumai)](https://twitter.com/codiumai)\n    <a href="https://github.com/Codium-ai/cover-agent/commits/main">\n    <img alt="GitHub" src="https://img.shields.io/github/last-commit/Codium-ai/cover-agent/main?style=for-the-badge" height="20">\n    </a>\n</div>\n\n## Table of Contents\n- [News and Updates](#news-and-updates)\n- [Overview](#overview)\n- [Installation and Usage](#installation-and-usage)\n- [Development](#development)\n- [Roadmap](#roadmap)\n\n\n## News and Updates\n\n### 2024-06-05:\nThe logic and prompts for adding new imports for the generated tests have been improved.\n\nWe also added a [usage examples](docs/usage_examples.md) file, with more elaborate examples of how to use the Cover Agent.\n\n### 2024-06-01:\nAdded support for comprehensive logging to [Weights and Biases](https://wandb.ai/). Set the `WANDB_API_KEY` environment variable to enable this feature.\n\n### 2024-05-26:\nCover-Agent now supports nearly any LLM model in the world, using [LiteLLM](#using-other-llms) package.\n\nNotice that GPT-4 outperforms almost any open-source model in the world when it comes to code tasks and following complicated instructions.\nHowever, we updated the post-processing scripts to be more comprehensive, and were able to successfully run the [baseline script](#running-the-code) with `llama3-8B` and `llama3-70B models`, for example.\n\n### 2024-05-09: \nThis repository includes the first known implementation of TestGen-LLM, described in the paper [Automated Unit Test Improvement using Large Language Models at Meta](https://arxiv.org/abs/2402.09171).\n\n# Cover-Agent\nWelcome to Cover-Agent. This focused project utilizes Generative AI to automate and enhance the generation of tests (currently mostly unit tests), aiming to streamline development workflows. Cover-Agent can run via a terminal, and is planned to be integrated into popular CI platforms.\n[![Test generation xxx](https://www.codium.ai/wp-content/uploads/2024/05/CodiumAI-CoverAgent-v240519-small-loop.gif)](https://youtu.be/fIYkSEJ4eqE?feature=shared)\n\nWe invite the community to collaborate and help extend the capabilities of Cover Agent, continuing its development as a cutting-edge solution in the automated unit test generation domain. We also wish to inspire researchers to leverage this open-source tool to explore new test-generation techniques.\n\n\n## Overview\nThis tool is part of a broader suite of utilities designed to automate the creation of unit tests for software projects. Utilizing advanced Generative AI models, it aims to simplify and expedite the testing process, ensuring high-quality software development. The system comprises several components:\n1. **Test Runner:** Executes the command or scripts to run the test suite and generate code coverage reports.\n2. **Coverage Parser:** Validates that code coverage increases as tests are added, ensuring that new tests contribute to the overall test effectiveness.\n3. **Prompt Builder:** Gathers necessary data from the codebase and constructs the prompt to be passed to the Large Language Model (LLM).\n4. **AI Caller:** Interacts with the LLM to generate tests based on the prompt provided.\n\n## Installation and Usage\n### Requirements\nBefore you begin, make sure you have the following:\n- `OPENAI_API_KEY` set in your environment variables, which is required for calling the OpenAI API.\n- Code Coverage tool: A Cobertura XML code coverage report is required for the tool to function correctly.\n  - For example, in Python one could use `pytest-cov`. Add the `--cov-report=xml` option when running Pytest.\n  - Note: We are actively working on adding more coverage types but please feel free to open a PR and contribute to `cover_agent/CoverageProcessor.py`\n\nIf running directly from the repository you will also need:\n- Python installed on your system.\n- Poetry installed for managing Python package dependencies. Installation instructions for Poetry can be found at [https://python-poetry.org/docs/](https://python-poetry.org/docs/).\n\n### Standalone Runtime\nThe Cover Agent can be installed as a Python Pip package or run as a standalone executable.\n\n#### Python Pip\nTo install the Python Pip package directly via GitHub run the following command:\n```\npip install git+https://github.com/Codium-ai/cover-agent.git\n```\n\n#### Binary\nThe binary can be run without any Python environment installed on your system (e.g. within a Docker container that does not contain Python). You can download the release for your system by navigating to the project\'s [release page](https://github.com/Codium-ai/cover-agent/releases).\n\n### Repository Setup\nRun the following command to install all the dependencies and run the project from source:\n```shell\npoetry install\n```\n\n### Running the Code\nAfter downloading the executable or installing the Pip package you can run the Cover Agent to generate and validate unit tests. Execute it from the command line by using the following command:\n```shell\ncover-agent \\\n  --source-file-path "<path_to_source_file>" \\\n  --test-file-path "<path_to_test_file>" \\\n  --code-coverage-report-path "<path_to_coverage_report>" \\\n  --test-command "<test_command_to_run>" \\\n  --test-command-dir "<directory_to_run_test_command>" \\\n  --coverage-type "<type_of_coverage_report>" \\\n  --desired-coverage <desired_coverage_between_0_and_100> \\\n  --max-iterations <max_number_of_llm_iterations> \\\n  --included-files "<optional_list_of_files_to_include>"\n```\n\nYou can use the example code below to try out the Cover Agent.\n(Note that the [usage_examples](docs/usage_examples.md) file provides more elaborate examples of how to use the Cover Agent)\n\n#### Python\n\nFollow the steps in the README.md file located in the `templated_tests/python_fastapi/` directory to setup an environment, then return to the root of the repository, and run the following command to add tests to the **python fastapi** example:\n```shell\ncover-agent \\\n  --source-file-path "templated_tests/python_fastapi/app.py" \\\n  --test-file-path "templated_tests/python_fastapi/test_app.py" \\\n  --code-coverage-report-path "templated_tests/python_fastapi/coverage.xml" \\\n  --test-command "pytest --cov=. --cov-report=xml --cov-report=term" \\\n  --test-command-dir "templated_tests/python_fastapi" \\\n  --coverage-type "cobertura" \\\n  --desired-coverage 70 \\\n  --max-iterations 10\n```\n\n#### Go\n\nFor an example using **go** `cd` into `templated_tests/go_webservice`, set up the project following the `README.md`.\nTo work with coverage reporting, you need to install `gocov` and `gocov-xml`. Run the following commands to install these tools:\n```shell\ngo install github.com/axw/gocov/gocov@v1.1.0\ngo install github.com/AlekSi/gocov-xml@v1.1.0\n```\nand then run the following command:\n```shell\ncover-agent \\\n  --source-file-path "app.go" \\\n  --test-file-path "app_test.go" \\\n  --code-coverage-report-path "coverage.xml" \\\n  --test-command "go test -coverprofile=coverage.out && gocov convert coverage.out | gocov-xml > coverage.xml" \\\n  --test-command-dir $(pwd) \\\n  --coverage-type "cobertura" \\\n  --desired-coverage 70 \\\n  --max-iterations 1\n```\n\n#### Java\nFor an example using **java** `cd` into `templated_tests/java_gradle`, set up the project following the [README.md](templated_tests/java_gradle/README.md).\nTo work with jacoco coverage reporting, follow the [README.md](templated_tests/java_gradle/README.md) Requirements section:\nand then run the following command:\n```shell\ncover-agent \\\n  --source-file-path="src/main/java/com/davidparry/cover/SimpleMathOperations.java" \\\n  --test-file-path="src/test/groovy/com/davidparry/cover/SimpleMathOperationsSpec.groovy" \\\n  --code-coverage-report-path="build/reports/jacoco/test/jacocoTestReport.csv" \\\n  --test-command="./gradlew clean test jacocoTestReport" \\\n  --test-command-dir=$(pwd) \\\n  --coverage-type="jacoco" \\\n  --desired-coverage=70 \\\n  --max-iterations=1\n```\n\n### Outputs\nA few debug files will be outputted locally within the repository (that are part of the `.gitignore`)\n* `run.log`: A copy of the logger that gets dumped to your `stdout`\n* `test_results.html`: A results table that contains the following for each generated test:\n  * Test status\n  * Failure reason (if applicable)\n  * Exit code, \n  * `stderr`\n  * `stdout`\n  * Generated test\n\n### Additional logging\nIf you set an environment variable `WANDB_API_KEY`, the prompts, responses, and additional information will be logged to [Weights and Biases](https://wandb.ai/).\n\n### Using other LLMs\nThis project uses LiteLLM to communicate with OpenAI and other hosted LLMs (supporting 100+ LLMs to date). To use a different model other than the OpenAI default you\'ll need to:\n1. Export any environment variables needed by the supported LLM [following the LiteLLM instructions](https://litellm.vercel.app/docs/proxy/quick_start#supported-llms).\n2. Call the name of the model using the `--model` option when calling Cover Agent.\n\nFor example (as found in the [LiteLLM Quick Start guide](https://litellm.vercel.app/docs/proxy/quick_start#supported-llms)):\n```shell\nexport VERTEX_PROJECT="hardy-project"\nexport VERTEX_LOCATION="us-west"\n\ncover-agent \\\n  ...\n  --model "vertex_ai/gemini-pro"\n```\n\n#### OpenAI Compatible Endpoint\n```shell\nexport OPENAI_API_KEY="<your api key>" # If <your-api-base> requires an API KEY, set this value.\n\ncover-agent \\\n  ...\n  --model "openai/<your model name>" \\\n  --api-base "<your-api-base>"\n```\n\n\n## Development\nThis section discusses the development of this project.\n\n### Versioning\nBefore merging to main make sure to manually increment the version number in `cover_agent/version.txt` at the root of the repository.\n\n### Running Tests\nSet up your development environment by running the `poetry install` command as you did above. \n\nNote: for older versions of Poetry you may need to include the `--dev` option to install Dev dependencies.\n\nAfter setting up your environment run the following command:\n```\npoetry run pytest --junitxml=testLog.xml --cov=templated_tests --cov=cover_agent --cov-report=xml --cov-report=term --log-cli-level=INFO\n```\nThis will also generate all logs and output reports that are generated in `.github/workflows/ci_pipeline.yml`.\n\n### Building the binary locally\nYou can build the binary locally simply by invoking the `make installer` command. This will run PyInstaller locally on your machine. Ensure that you have set up the poetry project first (i.e. running `poetry install`).\n\n## Roadmap\nBelow is the roadmap of planned features, with the current implementation status:\n\n- [x] Automatically generates unit tests for your software projects, utilizing advanced AI models to ensure comprehensive test coverage and quality assurance. (similar to Meta)\n  - [x] Being able to generate tests for different programming languages\n  - [ ] Being able to deal with a large variety of testing scenarios\n  - [ ] Generate a behavior analysis for the code under test, and generate tests accordingly\n  - [ ] Check test flakiness, e.g. by running 5 times as suggested by TestGen-LLM\n- [ ] Cover more test generation pains\n  - [ ] Generate new tests that are focused on the PR changeset\n  - [ ] Run over an entire repo/code-base and attempt to enhance all existing test suites\n- [ ] Improve usability\n  - [ ] Connectors for GitHub Actions, Jenkins, CircleCI, Travis CI, and more\n  - [ ] Integrate into databases, APIs, OpenTelemetry and other sources of data to extract relevant i/o for the test generation\n  - [ ] Add a setting file\n\n## CodiumAI\nCodiumAI\'s mission is to enable busy dev teams to increase and maintain their code integrity.\nWe offer various tools, including "Pro" versions of our open-source tools, which are meant to handle enterprise-level code complexity and are multi-repo codebase aware.\n',
    'author': 'CodiumAI',
    'author_email': 'tal.r@codium.ai',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'None',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.9,<3.13',
}


setup(**setup_kwargs)

